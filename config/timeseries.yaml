paths: 
  x_path: "./data/Processed/x_processed.xlsx"
  y_path: "./data/Processed/y_processed.xlsx"

dataloader: 
  shuffle: true
  num_workers: 1

model: 
  output_window: 24  
  batch_size: 32     # number of samples per batch; batch_size = number of samples the model processes before updating weights.
  lag: 0
  length: 96
  # output_size: the number of neurons in the final layer
  hidden_size: 128   # hidden_size = h = number of dimensions of the vector that the LSTM "remembers" and passes to the next step/layer
  output_size: 24
  epochs: 40         # how many times the model weights are updated (full passes through the dataset)
  learning_rate: 0.001  # step size for the optimizer
  dropout: 0.3       # percentage of neurons randomly deactivated to prevent overfitting